{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d5cfae4-eacf-4a31-8a60-61da9488586f",
   "metadata": {},
   "source": [
    "# Bag Of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d83f196-6aec-4385-b76c-9c394fe8afe3",
   "metadata": {},
   "source": [
    "#### Here dont have numerical values, we have text which we want to transform to numeric values\n",
    "* Bag of words - takes sentences and finds unique words in that sentence and transform to vectors (basic approach)<br>\n",
    "  '<b>This is a book, This book is great' = BoW('This is a book great')</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6146717-fa7c-4beb-a20f-a2cbfe75397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a8bd14-a005-4cb8-917d-09ca8c3bf44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class category:\n",
    "    Mobile  = 'Mobile'\n",
    "    Laptop = 'Laptop'\n",
    "    \n",
    "X = ['This is a mobile', 'I like this mobile', 'This is a great laptop', 'This is my favourite laptop']\n",
    "y = [category.Mobile, category.Mobile, category.Laptop, category.Laptop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dafed08-cfb4-4aa7-8d9f-a502ad82fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary=True)\n",
    "X_train = cv.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ee7583c-e987-44af-b9f8-1bddb7c340fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['favourite' 'great' 'is' 'laptop' 'like' 'mobile' 'my' 'this']\n",
      "[[0 0 1 0 0 1 0 1]\n",
      " [0 0 0 0 1 1 0 1]\n",
      " [0 1 1 1 0 0 0 1]\n",
      " [1 0 1 1 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names_out())\n",
    "print(X_train.toarray())\n",
    "\n",
    "# This gives an array which is sorted by there occurence in the sentence - ex : is occured twice so, 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a262d799-51b2-4707-9ef0-61c7ef9fdd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e34f49-c110-40f2-8a48-07091f114c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mobile'], dtype='<U6')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = cv.transform(['Gaming mobiles are cool'])\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4668049-55e8-41cf-a839-bfe3f00460f0",
   "metadata": {},
   "source": [
    "#### There are many things we can add to this but this is just a basic example of how bag of words is working\n",
    "#### More occurence(sentences) we feed, more cleaning we do --> will lead to a good model\n",
    "#### Above example is of UNIGRAM - which takes 1 word at a time, Another one is BIGRAM - which takes 2 words\n",
    "UNIGRAM - 'i like this' --> 'i like this', BIGRAM - 'i like this' --> 'i like, like this'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f13a4e-71be-4a7d-b7ba-f073cb80fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_with_ngram = CountVectorizer(binary=True, ngram_range = (1, 2))\n",
    "X_train_ngram = cv_with_ngram.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b352575-133b-4069-b307-22bef0ea7d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['favourite', 'favourite laptop', 'great', 'great laptop', 'is',\n",
       "       'is great', 'is mobile', 'is my', 'laptop', 'like', 'like this',\n",
       "       'mobile', 'my', 'my favourite', 'this', 'this is', 'this mobile'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_with_ngram.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "072badf3-29ec-4963-ae87-622030635d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ngram.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cda621-06b4-4ec2-8678-178898152529",
   "metadata": {},
   "source": [
    "#### BIGRAMS can be useful when we want to understand the tone of a sentence\n",
    "#### EX : sentence = 'this is not cool' || Unigram : 'this, is, not, cool', bigram : 'this is, is not, not cool' || As we see it changes the tone of the sentence<b>\n",
    "\n",
    "#### Bag of Words is great when the test data has words on which model was trained but if we pass in any word which was not seen during the training pass, then Bag of Words may not properly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02214795-4f4f-4dd1-a687-14de56b5d072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mobile'], dtype='<U6')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = cv.transform(['I like 15 inch laptops'])\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e029297-6efb-485d-8f48-5e7ae64a6926",
   "metadata": {},
   "source": [
    "# Word Vector\n",
    "#### It tries to capture the semantic meaning of the words in the vectors<br>\n",
    "\n",
    "#### Lets say we have some sentences which are for mobile:\n",
    "'Calling is very good', 'It has SnapDragon', 'It is of 6-inches'<br>\n",
    "Here WordVector will take more than 1 words and will try to relate them with the Mobile, like SnapDragon, calling, 6-inches often related to mobiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ade9cae-1b1d-4b3f-9299-7b9ec5c4bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d25c16ed-666a-4f8b-b4d2-c568d6ce3a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a mobile', 'I like this mobile', 'This is a great laptop', 'This is my favourite laptop']\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84ba0f93-d171-42f9-81a2-f906377af842",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [nlp(txt) for txt in X]\n",
    "train_spacy = [x.vector for x in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24368635-c1f4-450a-a774-4ea19867ab86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47c024c7-64be-4143-ab66-b7a9ada640e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_spacy = svm.SVC(kernel = 'linear')\n",
    "clf_spacy.fit(train_spacy, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "126d333a-ed02-479f-a4eb-fa94d387c773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Laptop'], dtype='<U6')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = ['It runs on linux']\n",
    "test_docs = [nlp(txt) for txt in X_test]\n",
    "test_vectors = [x.vector for x in test_docs]\n",
    "\n",
    "clf_spacy.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f4576f-ebbb-4ac7-903a-e605dd10684a",
   "metadata": {},
   "source": [
    "# Regexes\n",
    "Pattern matching of strings, \n",
    "Phone number, emails etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c53f951f-c172-434c-b404-dca86fc21cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nakdldlnm']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "regex = re.compile(r'na[^\\s]') # ^ - not and \\s - for empty space\n",
    "sentence = ['anm', 'ahnsm', 'nakdldlnm']\n",
    "\n",
    "matches = []\n",
    "for i in sentence:\n",
    "    if re.match(regex, i):\n",
    "        matches.append(i)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660f2da5-26ed-418b-ac58-d2c9a9eefe37",
   "metadata": {},
   "source": [
    "# Stemming / Lemmatization\n",
    "Techniques to normalize text<br>\n",
    "reading - read, Books - book <br>\n",
    "Stories - (Stori = Stemming and Story = Lemmatization)<br>\n",
    "We can use this in our cleaning process of the corpus, it can help increase the accuracy also model will have to take less words to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb49e840-ea44-4e06-bbef-a0c11005ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c59ae51-0b49-4312-85b9-b7d34c05a956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drive', 'the', 'car']\n",
      "drive the car\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "sentence = 'Driving the car'\n",
    "\n",
    "words = word_tokenize(sentence) # works like split method\n",
    "\n",
    "stemmed_words = []\n",
    "for i in words:\n",
    "    stemmed_words.append(stemmer.stem(i))\n",
    "\n",
    "print(stemmed_words)\n",
    "print(' '.join(stemmed_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "194990d8-36c2-43e2-9199-582abdbe48ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drive', 'the', 'car']\n",
      "drive the car\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "sentence = 'driving the car'\n",
    "\n",
    "words = word_tokenize(sentence) # works like split method\n",
    "\n",
    "lemmatized_words = []\n",
    "for i in words:\n",
    "    lemmatized_words.append(lemmatizer.lemmatize(i, pos='v')) # specifying verb to lemmatize\n",
    "\n",
    "print(lemmatized_words)\n",
    "print(' '.join(lemmatized_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b6a73d-8ea7-442c-b188-bb2008641bac",
   "metadata": {},
   "source": [
    "# Stopwords removal\n",
    "Set of most common words in english == this, that, is, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79edf156-13d6-463e-a6d5-7cf44e61ffea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'my', 'disciple', ',', 'are', 'you', 'doing', 'good']\n",
      "['Hello', 'disciple', ',', 'good']\n",
      "Hello disciple , good\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "sentence = 'Hello my disciple, are you doing good'\n",
    "words = word_tokenize(sentence)\n",
    "\n",
    "remove_stopwords = []\n",
    "for i in words:\n",
    "    if i not in stop_words:\n",
    "        remove_stopwords.append(i)\n",
    "\n",
    "print(words)\n",
    "print(remove_stopwords)\n",
    "print(' '.join(remove_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dab5f4-fd0f-4326-9280-7e912f1d3aa6",
   "metadata": {},
   "source": [
    "# TextBlob\n",
    "Natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01883ed0-c0a0-4f5b-8dde-04cf0f3cb5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"this is a Sentence\")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# While using this techniques, it is better to lower() the words and use this techniques on top of that for better result\n",
    "sentence = 'this is a Senetence'\n",
    "tb_sentence = TextBlob(sentence)\n",
    "\n",
    "tb_sentence.correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0796f919-362e-4ef5-b19b-dce860f99bd2",
   "metadata": {},
   "source": [
    "Polarity is the output that lies between [-1,1], where -1 refers to negative sentiment and +1 refers to positive sentiment<br>Subjectivity is the output that lies within [0,1] and refers to personal opinions and judgments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a62fec1-db02-4047-b4b9-5d50a1107e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.09374999999999999, subjectivity=0.34375)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'I love how India tackled economic crisis, when other countries were in trouble'\n",
    "TextBlob(sent).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7876165-3a94-4b70-b900-d6974f320450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('love', 'VBP'),\n",
       " ('how', 'WRB'),\n",
       " ('India', 'NNP'),\n",
       " ('tackled', 'VBD'),\n",
       " ('economic', 'JJ'),\n",
       " ('crisis', 'NN'),\n",
       " ('when', 'WRB'),\n",
       " ('other', 'JJ'),\n",
       " ('countries', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('trouble', 'NN')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(sent).tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266c0e1-e42a-4c74-8064-43c8febbb3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use RNN and Attention for better understanding of a text\n",
    "# Transformer Architectures - BERT, OpenAI-ChatGPT, ElMo\n",
    "# Spacy transformers and HuggingFace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
